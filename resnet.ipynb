{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e771ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c604e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam sınıf sayısı: 26\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 1. Veri Hazırlığı ve Augmentasyon\n",
    "####################################\n",
    "# Resimler 28x28 boyutunda; veri augmentasyonu ve normalize işlemleri uygulanıyor.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Resimler zaten tek kanallı olabilir; emin olmak için kullanıldı.\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Klasör yapınız:\n",
    "train_dataset = datasets.ImageFolder(root='train_images', transform=train_transforms)\n",
    "test_dataset  = datasets.ImageFolder(root='test_images', transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Toplam sınıf sayısı:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205eb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# 2. Basit ResNet Modeli Tanımı\n",
    "####################################\n",
    "# Residual blok tanımı\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Düzeltilmiş _make_layer fonksiyonu:\n",
    "def _make_layer(block, in_channels, out_channels, blocks, stride):\n",
    "    layers = []\n",
    "    # İlk bloğun giriş kanalı belirtilen in_channels, çıkışı out_channels\n",
    "    layers.append(block(in_channels, out_channels, stride))\n",
    "    for i in range(1, blocks):\n",
    "        layers.append(block(out_channels, out_channels))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Basitleştirilmiş ResNet mimarisi\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        # İlk conv katmanı: 28x28 görüntüler için uygun ayar (kanal sayısı: 1 -> 16)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Layer1: giriş kanalı 16, çıkış kanalı 16\n",
    "        self.layer1 = _make_layer(block, in_channels=16, out_channels=16, blocks=layers[0], stride=1)\n",
    "        # Layer2: giriş kanalı 16, çıkış kanalı 32 (stride ile downsampling)\n",
    "        self.layer2 = _make_layer(block, in_channels=16, out_channels=32, blocks=layers[1], stride=2)\n",
    "        # Layer3: giriş kanalı 32, çıkış kanalı 64 (stride ile downsampling)\n",
    "        self.layer3 = _make_layer(block, in_channels=32, out_channels=64, blocks=layers[2], stride=2)\n",
    "        # Global average pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # [B, 16, 28, 28]\n",
    "        x = self.layer1(x)                      # [B, 16, 28, 28]\n",
    "        x = self.layer2(x)                      # [B, 32, 14, 14]\n",
    "        x = self.layer3(x)                      # [B, 64, 7, 7] (örnek boyutlar, padding/stride ayarlarına bağlı)\n",
    "        x = self.avgpool(x)                     # [B, 64, 1, 1]\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271234f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleResNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Örneğin, her residual katmanda 1 blok kullanılarak model oluşturuluyor.\n",
    "resnet = SimpleResNet(BasicBlock, [1, 1, 1], num_classes=num_classes)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3f5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.6189, Test Loss: 0.2805, Test Accuracy: 0.9195\n",
      "Epoch [2/20], Train Loss: 0.5045, Test Loss: 0.2464, Test Accuracy: 0.9277\n",
      "Epoch [3/20], Train Loss: 0.4410, Test Loss: 0.2414, Test Accuracy: 0.9290\n",
      "Epoch [4/20], Train Loss: 0.4040, Test Loss: 0.2141, Test Accuracy: 0.9370\n",
      "Epoch [5/20], Train Loss: 0.3749, Test Loss: 0.1981, Test Accuracy: 0.9408\n",
      "Epoch [6/20], Train Loss: 0.3540, Test Loss: 0.1906, Test Accuracy: 0.9450\n",
      "Epoch [7/20], Train Loss: 0.3417, Test Loss: 0.1688, Test Accuracy: 0.9511\n",
      "Epoch [8/20], Train Loss: 0.3301, Test Loss: 0.1682, Test Accuracy: 0.9510\n",
      "Epoch [9/20], Train Loss: 0.3197, Test Loss: 0.1758, Test Accuracy: 0.9479\n",
      "Epoch [10/20], Train Loss: 0.3100, Test Loss: 0.1686, Test Accuracy: 0.9509\n",
      "Epoch [11/20], Train Loss: 0.3047, Test Loss: 0.1534, Test Accuracy: 0.9543\n",
      "Epoch [12/20], Train Loss: 0.2983, Test Loss: 0.1542, Test Accuracy: 0.9564\n",
      "Epoch [13/20], Train Loss: 0.2962, Test Loss: 0.1521, Test Accuracy: 0.9569\n",
      "Epoch [14/20], Train Loss: 0.2899, Test Loss: 0.1495, Test Accuracy: 0.9573\n",
      "Epoch [15/20], Train Loss: 0.2881, Test Loss: 0.1525, Test Accuracy: 0.9548\n",
      "Epoch [16/20], Train Loss: 0.2832, Test Loss: 0.1490, Test Accuracy: 0.9570\n",
      "Epoch [17/20], Train Loss: 0.2785, Test Loss: 0.1459, Test Accuracy: 0.9581\n",
      "Epoch [18/20], Train Loss: 0.2786, Test Loss: 0.1508, Test Accuracy: 0.9564\n",
      "Epoch [19/20], Train Loss: 0.2748, Test Loss: 0.1499, Test Accuracy: 0.9564\n",
      "Epoch [20/20], Train Loss: 0.2737, Test Loss: 0.1492, Test Accuracy: 0.9570\n",
      "ResNet modeli eğitildi ve en iyi ağırlıklar 'best_resnet_model.pth' olarak kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 3. Model Eğitim Döngüsü ve Kaydetme\n",
    "####################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001, weight_decay=1e-4)  # weight_decay L2 regularizasyon için\n",
    "\n",
    "num_epochs = 20\n",
    "best_test_loss = np.inf\n",
    "patience = 5\n",
    "counter = 0  # erken durdurma için\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Test/Doğrulama adımı\n",
    "    resnet.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images, labels\n",
    "            outputs = resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Erken durdurma: Eğer test loss iyileşmezse art arda patience kadar epoch sonrasında eğitim durdurulur.\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        counter = 0\n",
    "        # En iyi modelin ağırlıklarını kaydet\n",
    "        torch.save(resnet.state_dict(), \"best_resnet_model.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Erken durdurma tetiklendi!\")\n",
    "            break\n",
    "\n",
    "print(\"ResNet modeli eğitildi ve en iyi ağırlıklar 'best_resnet_model.pth' olarak kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4bc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1169    0    0    1    0    3    0   14    0    0    2    0    2    2\n",
      "     1    1    2    2    0    0    0    1    0    0    0    0]\n",
      " [   3 1145    1    9    7    0    4    0    0    0    0    0    0    0\n",
      "     9    2    4   14    2    0    0    0    0    0    0    0]\n",
      " [   0    0 1183    0    3    0    1    0    1    0    0    7    0    0\n",
      "     1    0    0    0    0    0    2    0    0    0    1    1]\n",
      " [   9    3    1 1088    0    1    0    1    0    3    0    0    3    2\n",
      "    76    3    6    0    1    0    0    1    0    0    2    0]\n",
      " [   0    0    6    0 1169   16    5    0    1    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    2]\n",
      " [   0    0    2    0    7 1171    2    0    0    2    0    2    0    0\n",
      "     0    4    2    2    2    2    0    0    0    0    2    0]\n",
      " [   1    8   10    2    5    1 1148    1    0    0    0    0    0    0\n",
      "     2    5   11    2    2    0    2    0    0    0    0    0]\n",
      " [   1    0    0    0    0    2    0 1178    1    1    1    0    3    7\n",
      "     0    0    0    0    0    1    0    1    0    0    4    0]\n",
      " [   0    0    4    0    4    2    0    6 1122    6    0   50    0    0\n",
      "     0    2    0    0    0    4    0    0    0    0    0    0]\n",
      " [   0    1    1    1    0    1    0    3   21 1117    0    8    0    1\n",
      "     0    0    0    0   13    9    7   11    0    0    2    4]\n",
      " [   1    0    2    0    0    7    0    8    0    0 1168    3    0    1\n",
      "     0    0    0    4    0    0    1    2    0    2    0    1]\n",
      " [   2    0   11    0    0    2    0    0  210    1    2  960    0    0\n",
      "     0    1    0    1    0    5    1    0    0    2    0    2]\n",
      " [   2    0    0    1    2    1    0   10    0    0    0    0 1176    7\n",
      "     0    0    0    0    0    0    0    0    1    0    0    0]\n",
      " [   1    0    0    1    0    0    0   10    0    1    3    2   18 1145\n",
      "     0    1    0    1    0    0   11    2    2    0    1    1]\n",
      " [   0    0    2   12    0    0    1    0    2    0    0    0    0    0\n",
      "  1168    0    8    0    0    1    6    0    0    0    0    0]\n",
      " [   1    2    0    7    0    6    1    0    1    2    0    0    2    0\n",
      "     0 1171    4    0    0    0    0    0    0    0    2    1]\n",
      " [   1    4    0    2    0    0    7    0    0    0    0    0    0    0\n",
      "    14    2 1165    3    0    0    2    0    0    0    0    0]\n",
      " [  19    3    2    0    0    3    3    2    0    0    7    0    0    0\n",
      "     0    3    4 1149    0    0    1    0    0    0    1    3]\n",
      " [   1    2    3    0    1    0    2    0    1    3    0    1    0    2\n",
      "     0    0    0    1 1179    0    0    0    0    0    1    3]\n",
      " [   0    0    0    0    1    7    0    1    9    2    0    3    0    0\n",
      "     0    0    0    0    0 1169    0    0    0    1    7    0]\n",
      " [   0    0    0    2    0    0    0    1    0    1    2    0    4    6\n",
      "     3    0    0    0    2    0 1133   26    8    0    3    9]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    4\n",
      "     0    0    0    0    1    1    7 1171    0    0   15    0]\n",
      " [   0    0    1    0    0    0    1    4    0    1    0    1   18   11\n",
      "     0    0    1    0    0    0    2    1 1158    0    1    0]\n",
      " [   0    0    0    0    1    2    0    1    0    0   17    0    1    1\n",
      "     0    0    0    0    0    0    0    0    0 1155   20    2]\n",
      " [   0    1    0    0    0    1    0    7    1    4    2    1    3    7\n",
      "     0    1    0    0    2   13    9   14    0    3 1130    1]\n",
      " [   1    3    3    0    6    2    0    0    1    2    1    0    0    0\n",
      "     0    0    0    0    4    1    1    0    2    0    2 1171]]\n",
      "Confusion matrix 'confusion_matrix.png' olarak kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 4. Confusion Matrix Hesaplama ve Kaydetme\n",
    "####################################\n",
    "# Test verileri üzerinde modelin tahminlerini toplayıp confusion matrix oluşturuluyor.\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "resnet.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images\n",
    "        outputs = resnet(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Confusion matrix hesaplanıyor\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Confusion matrix'in görselleştirilmesi\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.close()\n",
    "print(\"Confusion matrix 'confusion_matrix.png' olarak kaydedildi.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bil443",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
